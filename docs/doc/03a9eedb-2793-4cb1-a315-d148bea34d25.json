{
    "summary": "The EfficientNetEncoder class initializes and processes images for feature extraction using pre-trained models, handles input image processing, and Film conditioning. It applies convolution and film layers if context is not None, and performs pooling before returning features.",
    "details": [
        {
            "comment": "This code defines an EfficientNet encoder class, which applies a pre-trained EfficientNet model for feature extraction. The EfficientNet models are configured via gin and the available models include 'b3'. The output size of the encoder is specified by 'sizes' dictionary.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/film_efficientnet/pretrained_efficientnet_encoder.py\":0-33",
            "content": "# Copyright 2022 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Encoder based on Efficientnet.\"\"\"\nfrom typing import Optional\nimport gin\nfrom robotics_transformer.film_efficientnet import film_conditioning_layer\nfrom robotics_transformer.film_efficientnet import film_efficientnet_encoder\nimport tensorflow as tf\n_MODELS = {\n    'b3': film_efficientnet_encoder.EfficientNetB3,\n}\n_SIZES = {\n    'b3': 300,\n}\n@gin.configurable\nclass EfficientNetEncoder(tf.keras.layers.Layer):\n  \"\"\"Applies a pretrained Efficientnet based encoder.\"\"\""
        },
        {
            "comment": "The code initializes a pretrained EfficientNet encoder model, allowing users to specify the variant (B0-B7), whether or not to freeze the pretrained weights, if film layers should be injected, which pretrained weights to use, if the top fully connected layer should be included, and if pooling should be applied.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/film_efficientnet/pretrained_efficientnet_encoder.py\":35-56",
            "content": "  def __init__(self,\n               model_variant: str = 'b3',\n               freeze: bool = False,\n               early_film: bool = True,\n               weights: Optional[str] = 'imagenet',\n               include_top: bool = False,\n               pooling: bool = True,\n               **kwargs):\n    \"\"\"Initialize the model.\n    Args:\n      model_variant: One of 'b0-b7' of the efficient encoders. See\n        https://arxiv.org/abs/1905.11946 to understand the variants.\n      freeze: Whether or not to freeze the pretrained weights (seems to not work\n        well).\n      early_film: Whether to inject film layers into the efficientnet encoder\n        (seems to be essential to getting strong performance).\n      weights: Which pretrained weights to use. Either 'imagenet', a path to the\n        pretrained weights, or None for from scratch.\n      include_top: Whether to add the top fully connected layer. If True, this\n        will cause encoding to fail and is used only for unit testing purposes.\n      pooling: If false, returns feature map before global average pooling"
        },
        {
            "comment": "This code defines the EfficientNetEncoder class, initializes its components based on the model variant and other parameters, and includes a method for preparing input images. The EfficientNetEncoder uses a convolutional layer followed by an EfficientNet instance from a predefined list of models, with optional Film conditioning applied early or not at all. It also checks that the input image shape is correct before processing it further.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/film_efficientnet/pretrained_efficientnet_encoder.py\":57-83",
            "content": "      **kwargs: Keras specific layer kwargs.\n    \"\"\"\n    super(EfficientNetEncoder, self).__init__(**kwargs)\n    if model_variant not in _MODELS:\n      raise ValueError(f'Unknown variant {model_variant}')\n    self.model_variant = model_variant\n    self.early_film = early_film\n    self.freeze = freeze\n    self.conv1x1 = tf.keras.layers.Conv2D(\n        filters=512,\n        kernel_size=(1, 1),\n        strides=(1, 1),\n        padding='SAME',\n        use_bias=False,\n        kernel_initializer=tf.keras.initializers.VarianceScaling())\n    self.net = _MODELS[model_variant](\n        include_top=include_top,\n        weights=weights,\n        include_film=early_film,\n    )\n    self.film_layer = film_conditioning_layer.FilmConditioning(num_channels=512)\n    self._pooling = pooling\n  def _prepare_image(self, image: tf.Tensor) -> tf.Tensor:\n    \"\"\"Resize the input image and check that the range is correct.\"\"\"\n    if len(image.shape) != 4 or image.shape[-1] != 3:\n      raise ValueError('Provided image should have shape (b, h, w, 3).')"
        },
        {
            "comment": "The code ensures the image is resized to a specified size, normalizes it within the range (0, 255), and passes it through an EfficientNet encoder for processing. If the image is too small or large, it raises a ValueError. The function also handles early filming if enabled.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/film_efficientnet/pretrained_efficientnet_encoder.py\":84-106",
            "content": "    size = _SIZES[self.model_variant]\n    if image.shape[1] < size / 4 or image.shape[2] < size / 4:\n      raise ValueError('Provided image is too small.')\n    if image.shape[1] > size * 4 or image.shape[2] > size * 4:\n      raise ValueError('Provided image is too large.')\n    image = tf.image.resize(image, (size, size))\n    c1 = tf.Assert(tf.reduce_max(image) <= 1, data=[tf.reduce_max(image)])\n    c2 = tf.Assert(tf.reduce_min(image) >= 0, data=[tf.reduce_min(image)])\n    with tf.control_dependencies([c1, c2]):\n      image *= 255  # The image is expected to be in range(0, 255).\n      image = film_efficientnet_encoder.preprocess_input(image)\n      return image\n  def _encode(self, image: tf.Tensor, context: tf.Tensor,\n              training: bool) -> tf.Tensor:\n    \"\"\"Run the image through the efficientnet encoder.\"\"\"\n    image = self._prepare_image(image)\n    if self.early_film:\n      return self.net((image, context), training=training)\n    return self.net(image, training=training)\n  def call(self,\n           image: tf.Tensor,"
        },
        {
            "comment": "This code defines a function that takes an image, optional context, and training state as input. If the model is frozen, it applies stop_gradient to the output of _encode function. Otherwise, it directly calls _encode. It then applies convolution and film layer if context is not None. Finally, if pooling is disabled, it returns the features; otherwise, it performs global average pooling on the features and returns the result.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/film_efficientnet/pretrained_efficientnet_encoder.py\":107-121",
            "content": "           context: Optional[tf.Tensor] = None,\n           training: bool = True) -> tf.Tensor:\n    if self.freeze:\n      features = tf.stop_gradient(self._encode(image, context, training))\n    else:\n      features = self._encode(image, context, training)\n    if context is not None:\n      features = self.conv1x1(features)\n      features = self.film_layer(features, context)\n    if not self._pooling:\n      return features\n    # Global average pool.\n    return tf.reduce_mean(features, [1, 2])"
        }
    ]
}