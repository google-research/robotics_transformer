{
    "summary": "This class defines `RT1ImageTokenizer` for image tokenization with EfficientNet and an optional token learner. It outputs the tokens_per_context_image, based on learned tokens or default 81. The function extracts embeddings from images using the tokenizer, reshapes the tokens into a 3D tensor, and returns the desired shaped image tokens.",
    "details": [
        {
            "comment": "This code defines a class `RT1ImageTokenizer` for image tokenization based on vocabulary size. It uses the EfficientNet model from the `robotics_transformer.film_efficientnet` module and optionally includes a `token_learner`. The embedding output dimension can be specified as an input parameter.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/tokenizers/image_tokenizer.py\":0-26",
            "content": "# Copyright 2022 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"A FiLM Efficientnet contextual image tokenizer used in Robotics Transformer 1.\n\"\"\"\nfrom typing import Optional\nfrom robotics_transformer.film_efficientnet import pretrained_efficientnet_encoder\nfrom robotics_transformer.tokenizers import token_learner\nimport tensorflow as tf\nclass RT1ImageTokenizer(tf.keras.layers.Layer):\n  \"\"\"Tokenizes based on vocab size.\"\"\"\n  def __init__(self,\n               embedding_output_dim: int,\n               use_token_learner: bool = False,"
        },
        {
            "comment": "This code instantiates an RT1ImageTokenizer with optional arguments such as embedding_output_dim and use_token_learner. It initializes the tokenizer's EfficientNetEncoder, token learner if use_token_learner is True, and returns tokens_per_context_image based on the number of learned tokens or a default value of 81.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/tokenizers/image_tokenizer.py\":27-59",
            "content": "               num_tokens: int = 8,\n               **kwargs):\n    \"\"\"Instantiates a RT1ImageTokenizer.\n    Args:\n      embedding_output_dim: The output size of the tokens.\n      use_token_learner: Whether to use token learner. See\n        https://arxiv.org/abs/2106.11297\n      num_tokens: Relevant only for token learner - the number of learned\n        tokens.\n      **kwargs: Keyword arguments to base class.\n    \"\"\"\n    super().__init__(**kwargs)\n    self._embedding_output_dim = embedding_output_dim\n    self._tokenizer = pretrained_efficientnet_encoder.EfficientNetEncoder(\n        pooling=False, early_film=True)\n    self._use_token_learner = use_token_learner\n    if self._use_token_learner:\n      self._num_tokens = num_tokens\n      self._token_learner = token_learner.TokenLearnerModule(\n          num_tokens=self._num_tokens)\n  @property\n  def tokens_per_context_image(self) -> int:\n    if self._use_token_learner:\n      num_tokens = self._num_tokens\n    else:\n      num_tokens = 81\n    return num_tokens\n  def __call__(self,"
        },
        {
            "comment": "This function takes in an image tensor and optionally a context tensor. It reshapes the image tensor, then if a context tensor is provided, it also reshapes it. The result is a token tensor based on the get_image_embeddings method, which is not shown here. The function returns tokens with shape (batch, t, num_tokens_per_timestep, embedding_dim).",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/tokenizers/image_tokenizer.py\":60-88",
            "content": "               image: tf.Tensor,\n               context: Optional[tf.Tensor] = None,\n               training: bool = False) -> tf.Tensor:\n    \"\"\"Gets image tokens.\n    Args:\n      image: Images of shape (b, t, h, w, 3) to tokenize.\n      context: An optional context vector (e.g., a natural language embedding).\n        Expected to have shape (b, t, embedding_dim).\n      training: Whether or not we are in training mode.\n    Returns:\n      tokens: has shape (batch, t, num_tokens_per_timestep, embedding_dim)\n    \"\"\"\n    image_shape = tf.shape(image)\n    b = image_shape[0]\n    t = image_shape[1]\n    h = image_shape[2]\n    w = image_shape[3]\n    c = image_shape[4]\n    # Fold the time axis into the batch axis.\n    image = tf.reshape(image, [b * t, h, w, c])\n    if context is not None:\n      context_rank = tf.rank(context)\n      assertion = tf.Assert(context_rank == 3, data=[context_rank])\n      with tf.control_dependencies([assertion]):\n        context = tf.reshape(context, [b * t, tf.shape(context)[-1]])\n    tokens = self.get_image_embeddings(image, context, training)"
        },
        {
            "comment": "The code defines a method to extract embeddings from images using a tokenizer and reshapes the resulting tokens into a 3D tensor. The `get_image_embeddings` function takes an image tensor, optional context tensor, and training flag as input, and returns the image tokens in the desired shape. The image is first transformed by the tokenizer, then reshaped to (-1, 81, 512) using tf.reshape.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/tokenizers/image_tokenizer.py\":89-111",
            "content": "    if self._use_token_learner:\n      tokens = self._token_learner(tokens, training)\n    # Unflatten the time axis, which was previously flattened into the batch.\n    tokens = tf.reshape(tokens, [b, t, tf.shape(tokens)[1], -1])\n    return tokens\n  def get_image_embeddings(self,\n                           image: tf.Tensor,\n                           context: Optional[tf.Tensor],\n                           training: bool = False) -> tf.Tensor:\n    \"\"\"Gets embeddings from image.\n    Args:\n      image: Expected to be float32 in range [0, 1] with shape (b, h, w, 3).\n      context: Expected to be float32 with shape (b, embedding_dim)\n      training: Whether or not we are in training mode.\n    Returns:\n      tokens of shape (b, num_tokens, emedding_dim)\n    \"\"\"\n    image_tokens = self._tokenizer(image, context=context, training=training)\n    image_tokens = tf.reshape(image_tokens, [-1, 81, 512])\n    return image_tokens"
        }
    ]
}