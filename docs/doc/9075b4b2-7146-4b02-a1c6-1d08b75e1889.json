{
    "summary": "The `RT1ActionTokenizer` class in the robotics_transformer library tokenizes and detokenizes actions, normalizing their values as necessary. It manages discrete and continuous dimensions, retains action order, initializes tokenization, and provides relevant information.",
    "details": [
        {
            "comment": "This code snippet is from the \"robotics_transformer/tokenizers/action_tokenizer.py\" file and defines a simple action tokenizer for Robotics Transformer 1. It converts actions into sequences of tokens, handling both discrete and continuous dimensions. Discrete dimensions are already tokenized while continuous dimensions are bucketed based on specified min and max values, using 'vocab_size' buckets.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/tokenizers/action_tokenizer.py\":0-24",
            "content": "# Copyright 2022 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"A simple action tokenizer used with Robotics Transformer 1.\nAs an example, if an action is:\nterminate = [0, 1]\nworld_vector = [0.9, 0.8, -0.3]\nrotation_delta = [-0.1, 0.2, .6]\ngripper_closedness = 0.9\nThen we build a sequence of tokens of length 8 [one for each dimension].\nThe int32 type action dimensions are already assumed discrete and tokenized,\nthe float dimensions are bucketed according to the specs min and max. Each\ndimension has 'vocab_size' buckets."
        },
        {
            "comment": "This code defines a class `RT1ActionTokenizer` that tokenizes actions based on vocabulary size. It takes an action spec, vocab size, and optional action order as input for initialization. The action order helps maintain the order of tokenized actions for detokenization and assembly back to the action tensor.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/tokenizers/action_tokenizer.py\":26-51",
            "content": "Currently, this tokenizer assumes one action spec and it is highly recommended\nto specify the 'action_order', eg [terminate, world_vector, rotation_delta,\ngripper_closedness]. Since after tokenization you lose that information, this\nwill be useful for debugging. Actions may also be subselected for prediction,\nsince not all actions are needed in the action_order.\n\"\"\"\nfrom typing import Optional\nfrom tensor2robot.utils import tensorspec_utils\nimport tensorflow as tf\nclass RT1ActionTokenizer:\n  \"\"\"Tokenizes based on vocab size.\"\"\"\n  def __init__(self,\n               action_spec: tensorspec_utils.TensorSpecStruct,\n               vocab_size: int,\n               action_order: Optional[list[str]] = None):\n    \"\"\"Instantiates an RT1ActionTokenizer.\n    Args:\n      action_spec: Tensor spec of the expected action tensor.\n      vocab_size: Number of buckets to discretize action to.\n      action_order: Order of the action names, used to discern the order of\n        tokenized actions to detokenize and assemble back to action tensor"
        },
        {
            "comment": "This code initializes an action tokenizer. It stores the action_spec and vocab_size, and checks if the action_order is provided. If not, it uses the keys of action_spec as the order. It then iterates over the action order to determine the number of tokens per action. If an action shape doesn't have a single dimension, it raises a ValueError. Finally, it measures the total number of action tokens in two different ways - by checking for int32 actions and calculating the total from non-int32 actions.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/tokenizers/action_tokenizer.py\":52-77",
            "content": "    \"\"\"\n    self._action_spec = action_spec\n    self._vocab_size = vocab_size\n    if action_order is None:\n      self._action_order = self._action_spec.keys()\n    else:\n      for action in action_order:\n        if action not in self._action_spec.keys():\n          raise ValueError('actions: %s not found in action_spec: %s' %\n                           (action, action_spec.keys()))\n        assert action in self._action_spec.keys()\n      self._action_order = action_order\n    self._tokens_per_action = 0\n    for action in self._action_order:\n      action_shape = self._action_spec[action].shape\n      if len(action_shape) != 1:\n        raise ValueError(\n            'Only action shapes with single dimension supported, got %s' %\n            action_shape)\n      if self._action_spec[action].dtype == tf.int32:\n        # Int32 actions are already assumed to be tokens.\n        self._tokens_per_action += 1\n      else:\n        self._tokens_per_action += action_shape[0]\n    # We measure # of action tokens in two different way. One is by checking"
        },
        {
            "comment": "This code checks if the number of action tokens calculated from 'action_order' and by looping through 'action_spec' are the same, ensuring 'action_order' is correctly configured. It also provides properties to access 'tokens_per_action', 'action_spec', and 'action_order', and a method to tokenize an action.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/tokenizers/action_tokenizer.py\":78-106",
            "content": "    # from action_order (above) and the other is by looping through the\n    # action spec (below). We aseert the # of action tokens are the same\n    # calculated by these two ways. This will assure action_order is correctly\n    # configured, otherwise, it will through an error in the assert.\n    num_action_token = 0\n    for spec in self._action_spec.values():\n      if spec.dtype == tf.int32:\n        num_action_token += 1\n      else:\n        num_action_token += spec.shape[-1]\n    tf.debugging.assert_equal(num_action_token, self._tokens_per_action)\n  @property\n  def tokens_per_action(self) -> int:\n    return self._tokens_per_action\n  @property\n  def action_spec(self) -> tensorspec_utils.TensorSpecStruct:\n    return self._action_spec\n  @property\n  def action_order(self) -> list[str]:\n    return self._action_order\n  def tokenize(self, action: tensorspec_utils.TensorSpecStruct) -> tf.Tensor:\n    \"\"\"Tokenizes an action.\"\"\"\n    action_tokens = []\n    for k in self._action_order:\n      a = action[k]  # a is [batch, actions_size]"
        },
        {
            "comment": "The code is tokenizing actions, assuming the dtype to determine whether the actions are already in token form or need conversion. For int32 dtype, it pads zeros and checks for valid tokens. Otherwise, for other dtypes, it normalizes the action values, discretizes them into a vocabulary size, and appends all actions into a single tensor.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/tokenizers/action_tokenizer.py\":107-126",
            "content": "      spec = self._action_spec[k]\n      if spec.dtype == tf.int32:\n        # Int32 actions are already assumed to be tokens, assume it is smaller\n        # than the vocab size, so all we need to do is pad zeros.\n        tf.debugging.assert_equal(1, tf.reduce_sum(a, axis=-1))\n        # extract the token [batch, 1]\n        token = tf.argmax(a, axis=-1, output_type=tf.int32)\n        tf.debugging.assert_less(token, self._vocab_size)\n        # Add a seq dimension [batch, 1]\n        token = tf.expand_dims(token, axis=-1)\n      else:\n        a = tf.clip_by_value(a, spec.minimum, spec.maximum)\n        # Normalize the action [batch, actions_size]\n        token = (a - spec.minimum) / (spec.maximum - spec.minimum)\n        # Bucket and discretize the action to vocab_size, [batch, actions_size]\n        token = tf.cast(token * (self._vocab_size - 1), tf.int32)\n      action_tokens.append(token)\n    # Append all actions, [batch, all_actions_size]\n    action_tokens = tf.concat(action_tokens, axis=-1)\n    return action_tokens"
        },
        {
            "comment": "This function detokenizes an action by iterating through the action_tokens, considering different data types. If the type is int32, it assumes the tokens are already present and performs necessary checks before converting them into one-hot encoded values. For other data types, it loops through the action dimensions, extracts and casts the corresponding tokens to float32.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/tokenizers/action_tokenizer.py\":128-150",
            "content": "  def detokenize(self,\n                 action_tokens: tf.Tensor) -> tensorspec_utils.TensorSpecStruct:\n    \"\"\"Detokenizes an action.\"\"\"\n    action = tensorspec_utils.TensorSpecStruct()\n    token_index = 0\n    for k in self._action_order:\n      spec = self._action_spec[k]\n      action_dim = spec.shape[0]\n      if spec.dtype == tf.int32:\n        # Int32 actions are already assumed to be tokens.\n        action[k] = action_tokens[..., token_index]\n        # A poor model may output tokens outside the allowed range, in that case\n        # set them to a default value, the 0 token in this case.\n        outside_range = tf.greater_equal(action[k], action_dim)\n        action[k] = tf.where(outside_range, tf.zeros_like(action[k]), action[k])\n        action[k] = tf.one_hot(\n            action[k], depth=action_dim, axis=-1, dtype=tf.int32)\n        token_index += 1\n      else:\n        actions = []\n        for _ in range(action_dim):\n          a = action_tokens[..., token_index:token_index + 1]\n          a = tf.cast(a, tf.float32)"
        },
        {
            "comment": "This code segment is part of the action_tokenizer class in the robotics_transformer library. It performs normalization and concatenation operations on a list of actions (represented as floats) based on specified minimum and maximum values, and appends them to a token index. The resulting list of normalized actions is then concatenated along the last axis and stored in the 'action' dictionary for later use.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/tokenizers/action_tokenizer.py\":151-156",
            "content": "          a = a / (self._vocab_size - 1)\n          a = (a * (spec.maximum - spec.minimum)) + spec.minimum\n          actions.append(a)\n          token_index += 1\n        action[k] = tf.concat(actions, axis=-1)\n    return action"
        }
    ]
}