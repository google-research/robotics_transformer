{
    "summary": "The code tests the image_tokenizer module by creating a tokenizer object with provided parameters, generating random images and context vectors, and checking the shape of resulting image tokens to ensure it produces appropriate outputs for the given input data.",
    "details": [
        {
            "comment": "The provided code is a test case for the image_tokenizer module in the robotics_transformer library. The test class, ImageTokenizerTest, is extending tf.test.TestCase and parameterized.TestCase to handle tensorflow testing features and parameterized tests. It contains one test function, testTokenize, which takes parameters such as output_dim, image_resolution, use_token_learner, and num_tokens. The purpose of this test is to verify the tokenization functionality of the image_tokenizer module.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/tokenizers/image_tokenizer_test.py\":0-25",
            "content": "# Copyright 2022 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Tests for image_tokenizer.\"\"\"\nfrom absl.testing import parameterized\nfrom robotics_transformer.tokenizers import image_tokenizer\nimport tensorflow as tf\nclass ImageTokenizerTest(tf.test.TestCase, parameterized.TestCase):\n  @parameterized.named_parameters(\n      ('sample_image', 512, 224, False, 8),\n      ('sample_image_token_learner', 512, 224, True, 8))\n  def testTokenize(self, output_dim, image_resolution, use_token_learner,\n                   num_tokens):"
        },
        {
            "comment": "This code is testing the image_tokenizer by creating a tokenizer object with given parameters, generating random images and context vectors, and then checking the shape of the resulting image tokens. It asserts that the shape matches the expected format based on whether token learning is used or not. The code ensures the tokenizer works correctly and produces appropriate outputs for the given input data.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/tokenizers/image_tokenizer_test.py\":26-45",
            "content": "    batch = 1\n    seq = 2\n    tokenizer = image_tokenizer.RT1ImageTokenizer(\n        embedding_output_dim=output_dim,\n        use_token_learner=use_token_learner,\n        num_tokens=num_tokens)\n    image = tf.random.normal(\n        shape=(batch, seq, image_resolution, image_resolution, 3))\n    image = tf.clip_by_value(image, 0.0, 1.0)\n    context_vector = tf.random.uniform((batch, seq, 512))\n    image_tokens = tokenizer(image, context_vector)\n    if use_token_learner:\n      self.assertEqual(image_tokens.shape, [batch, seq, num_tokens, 512])\n    else:\n      self.assertEqual(image_tokens.shape, [batch, seq, 81, 512])\nif __name__ == '__main__':\n  tf.test.main()"
        }
    ]
}