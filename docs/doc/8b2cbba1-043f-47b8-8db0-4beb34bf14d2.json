{
    "summary": "The code tests a transformer network's loss, inference, and causality using parameterized tests with different state specifications and observations. It creates an agent, sets parameters, generates masks, and asserts expected values while enabling eager execution.",
    "details": [
        {
            "comment": "This code is a test file for transformer networks in the robotics_transformer package. It imports necessary modules and sets up various parameters for testing, including batch size, observation names to inf observations mapping, state specs, and observations list.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/transformer_network_test.py\":0-21",
            "content": "# Copyright 2022 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Tests for networks.\"\"\"\nfrom absl.testing import parameterized\nfrom robotics_transformer import transformer_network\nfrom robotics_transformer.transformer_network_test_set_up import BATCH_SIZE\nfrom robotics_transformer.transformer_network_test_set_up import NAME_TO_INF_OBSERVATIONS\nfrom robotics_transformer.transformer_network_test_set_up import NAME_TO_STATE_SPECS\nfrom robotics_transformer.transformer_network_test_set_up import observations_list"
        },
        {
            "comment": "This code defines a test class for the TransformerNetworkTestUtils. It imports necessary modules, sets up parameters using @parameterized decorator from tensorflow/transform, and creates an instance of TransformerNetwork with input and output tensor specs. The class then tests the train loss call of the transformer network model.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/transformer_network_test.py\":22-45",
            "content": "from robotics_transformer.transformer_network_test_set_up import spec_names_list\nfrom robotics_transformer.transformer_network_test_set_up import state_spec_list\nfrom robotics_transformer.transformer_network_test_set_up import TIME_SEQUENCE_LENGTH\nfrom robotics_transformer.transformer_network_test_set_up import TransformerNetworkTestUtils\nimport tensorflow as tf\nfrom tf_agents.specs import tensor_spec\nclass TransformerNetworkTest(TransformerNetworkTestUtils):\n  # pylint:disable=g-complex-comprehension\n  @parameterized.named_parameters([{\n      'testcase_name': '_' + name,\n      'state_spec': spec,\n      'train_observation': obs,\n  } for (name, spec,\n         obs) in zip(spec_names_list(), state_spec_list(), observations_list())]\n                                 )\n  # pylint:enable=g-complex-comprehension\n  def testTransformerTrainLossCall(self, state_spec, train_observation):\n    network = transformer_network.TransformerNetwork(\n        input_tensor_spec=state_spec,\n        output_tensor_spec=self._action_spec,"
        },
        {
            "comment": "This code initializes a transformer network and asserts its variables, sets actions, performs inference, and tests the loss calculation. It uses a named parameterized test function to run multiple tests with different specifications.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/transformer_network_test.py\":46-71",
            "content": "        time_sequence_length=TIME_SEQUENCE_LENGTH)\n    network.create_variables()\n    self.assertNotEmpty(network.variables)\n    network.set_actions(self._train_action)\n    network_state = tensor_spec.sample_spec_nest(\n        network.state_spec, outer_dims=[BATCH_SIZE])\n    output_actions, network_state = network(\n        train_observation, step_type=None, network_state=network_state)\n    expected_shape = [2, 3]\n    self.assertEqual(network.get_actor_loss().shape,\n                     tf.TensorShape(expected_shape))\n    self.assertCountEqual(self._train_action.keys(), output_actions.keys())\n  # pylint:disable=g-complex-comprehension\n  @parameterized.named_parameters([{\n      'testcase_name': '_' + name,\n      'spec_name': name,\n  } for name in spec_names_list()])\n  # pylint:enable=g-complex-comprehension\n  def testTransformerInferenceLossCall(self, spec_name):\n    state_spec = NAME_TO_STATE_SPECS[spec_name]\n    observation = NAME_TO_INF_OBSERVATIONS[spec_name]\n    network = transformer_network.TransformerNetwork("
        },
        {
            "comment": "The code creates a transformer network, initializes its variables, sets actions for inference and tests the network's output. It also checks actor loss, compares input and output actions, and runs parameterized tests with different state specifications and observations.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/transformer_network_test.py\":72-98",
            "content": "        input_tensor_spec=state_spec,\n        output_tensor_spec=self._action_spec,\n        time_sequence_length=TIME_SEQUENCE_LENGTH,\n        action_order=[\n            'terminate_episode', 'world_vector', 'rotation_delta',\n            'gripper_closedness_action'\n        ])\n    network.create_variables()\n    self.assertNotEmpty(network.variables)\n    network.set_actions(self._inference_action)\n    # inference currently only support batch size of 1\n    network_state = tensor_spec.sample_spec_nest(\n        network.state_spec, outer_dims=[1])\n    output_actions, network_state = network(\n        observation, step_type=None, network_state=network_state)\n    tf.debugging.assert_equal(network.get_actor_loss(), 0.0)\n    self.assertCountEqual(self._inference_action.keys(), output_actions.keys())\n  # pylint:disable=g-complex-comprehension\n  @parameterized.named_parameters([{\n      'testcase_name': '_' + name,\n      'state_spec': spec,\n      'train_observation': obs,\n  } for name, spec, obs in zip(spec_names_list(), state_spec_list(),"
        },
        {
            "comment": "This code sets up a transformer network and asserts that it creates variables. It then initializes the actions, samples a batch of state specifications, passes in training observation to the network, adds summaries for training, and performs various parameterized tests.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/transformer_network_test.py\":99-126",
            "content": "                               observations_list())])\n  # pylint:enable=g-complex-comprehension\n  def testTransformerLogging(self, state_spec, train_observation):\n    network = transformer_network.TransformerNetwork(\n        input_tensor_spec=state_spec,\n        output_tensor_spec=self._action_spec,\n        time_sequence_length=TIME_SEQUENCE_LENGTH,\n        action_order=[\n            'terminate_episode', 'world_vector', 'rotation_delta',\n            'gripper_closedness_action'\n        ])\n    network.create_variables()\n    self.assertNotEmpty(network.variables)\n    network.set_actions(self._train_action)\n    network_state = tensor_spec.sample_spec_nest(\n        network.state_spec, outer_dims=[BATCH_SIZE])\n    _ = network(train_observation, step_type=None, network_state=network_state)\n    network.add_summaries(\n        train_observation,\n        network.get_aux_info(),\n        debug_summaries=True,\n        training=True)\n  # pylint:disable=g-complex-comprehension\n  @parameterized.named_parameters([{\n      'testcase_name': '_' + name,"
        },
        {
            "comment": "This code is testing the causality of a transformer network. It creates an instance of the network with input and output tensor specifications, then checks if the network has variables and extracts necessary parameters for testing. A helper function splits image and action tokens using given token counts and sequence length.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/transformer_network_test.py\":127-151",
            "content": "      'state_spec': spec,\n  } for name, spec in zip(spec_names_list(), state_spec_list())])\n  # pylint:enable=g-complex-comprehension\n  def testTransformerCausality(self, state_spec):\n    \"\"\"Tests the causality for the transformer.\n    Args:\n      state_spec: Which state spec to test the transformer with\n    \"\"\"\n    network = transformer_network.TransformerNetwork(\n        input_tensor_spec=state_spec,\n        output_tensor_spec=self._action_spec,\n        time_sequence_length=TIME_SEQUENCE_LENGTH)\n    network.create_variables()\n    self.assertNotEmpty(network.variables)\n    time_sequence_length = network._time_sequence_length\n    tokens_per_image = network._tokens_per_context_image\n    tokens_per_action = network._tokens_per_action\n    def _split_image_and_action_tokens(all_tokens):\n      image_start_indices = [(tokens_per_image + tokens_per_action) * k\n                             for k in range(time_sequence_length)]\n      image_tokens = tf.stack(\n          [all_tokens[i:i + tokens_per_image] for i in image_start_indices],"
        },
        {
            "comment": "The code above is part of a transformer network test, where it generates random tokens for image and actions. It splits the image and action tokens from a list of all tokens. Then it calls the transformer network to get output tokens without any zeroed-out input tokens. The context_image_tokens and action_tokens are obtained by splitting the all_tokens using image_start_indices and tokens_per_action. The image_tokens are one-hot encoded and reshaped to add a batch dimension.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/transformer_network_test.py\":152-176",
            "content": "          axis=0)\n      action_start_indices = [i + tokens_per_image for i in image_start_indices]\n      action_tokens = [\n          tf.stack([\n              all_tokens[i:i + tokens_per_action] for i in action_start_indices\n          ], 0)\n      ]\n      image_tokens = tf.one_hot(image_tokens, network._token_embedding_size)\n      # Remove extra dimension before the end once b/254902773 is fixed.\n      shape = image_tokens.shape\n      # Add batch dimension.\n      image_tokens = tf.reshape(image_tokens,\n                                [1] + shape[:-1] + [1] + shape[-1:])\n      return image_tokens, action_tokens\n    # Generate some random tokens for image and actions.\n    all_tokens = tf.random.uniform(\n        shape=[time_sequence_length * (tokens_per_image + tokens_per_action)],\n        dtype=tf.int32,\n        maxval=10,\n        minval=0)\n    context_image_tokens, action_tokens = _split_image_and_action_tokens(\n        all_tokens)\n    # Get the output tokens without any zeroed out input tokens.\n    output_tokens = network._transformer_call("
        },
        {
            "comment": "This code segment tests the transformer network by feeding it a time sequence of input tokens and checking if the output token remains unchanged when future input tokens are zeroed out. It ensures the network does not rely on future input tokens to produce the current output.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/transformer_network_test.py\":177-199",
            "content": "        context_image_tokens=context_image_tokens,\n        action_tokens=action_tokens,\n        attention_mask=network._default_attention_mask,\n        batch_size=1,\n        training=False)[0]\n    for t in range(time_sequence_length *\n                   (tokens_per_image + tokens_per_action)):\n      # Zero out future input tokens.\n      all_tokens_at_t = tf.concat(\n          [all_tokens[:t + 1],\n           tf.zeros_like(all_tokens[t + 1:])], 0)\n      context_image_tokens, action_tokens = _split_image_and_action_tokens(\n          all_tokens_at_t)\n      # Get the output tokens with zeroed out input tokens after t.\n      output_tokens_at_t = network._transformer_call(\n          context_image_tokens=context_image_tokens,\n          action_tokens=action_tokens,\n          attention_mask=network._default_attention_mask,\n          batch_size=1,\n          training=False)[0]\n      # The output token is unchanged if future input tokens are zeroed out.\n      self.assertAllEqual(output_tokens[:t + 1], output_tokens_at_t[:t + 1])"
        },
        {
            "comment": "The code defines a test function `testLossMasks` that creates an agent, sets specific parameters, generates masks for action tokens, and asserts the generated mask values match expected values. The code also enables eager execution.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/transformer_network_test.py\":201-227",
            "content": "  def testLossMasks(self):\n    self._define_specs()\n    self._create_agent()\n    image_tokens = 3\n    action_tokens = 2\n    self._agent._actor_network._time_sequence_length = 2\n    self._agent._actor_network._tokens_per_context_image = image_tokens\n    self._agent._actor_network._tokens_per_action = action_tokens\n    self._agent._actor_network._generate_masks()\n    self.assertAllEqual(\n        self._agent._actor_network._action_tokens_mask,\n        tf.constant([\n            image_tokens, image_tokens + 1, 2 * image_tokens + action_tokens,\n            2 * image_tokens + action_tokens + 1\n        ], tf.int32))\n    self._agent._actor_network._generate_masks()\n    self.assertAllEqual(\n        self._agent._actor_network._action_tokens_mask,\n        tf.constant([\n            image_tokens, image_tokens + 1, 2 * (image_tokens) + action_tokens,\n            2 * (image_tokens) + action_tokens + 1\n        ], tf.int32))\nif __name__ == '__main__':\n  # Useful to enable if running with ipdb.\n  tf.config.run_functions_eagerly(True)"
        },
        {
            "comment": "This code is invoking the main test function of TensorFlow library to execute all tests defined in the current file.",
            "location": "\"/media/root/Prima/works/robotics_transformer/docs/src/transformer_network_test.py\":228-228",
            "content": "  tf.test.main()"
        }
    ]
}